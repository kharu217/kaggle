{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üåæ Cotton Weed Detection Challenge - Starter Notebook\n",
    "\n",
    "## Quick Start Guide\n",
    "\n",
    "This notebook walks you through:\n",
    "1. **Environment Setup** - Install 3LC and required packages\n",
    "2. **Dataset Registration** - Create 3LC Tables for data management\n",
    "3. **Baseline Training** - Train YOLOv8n with run tracking\n",
    "4. **Generate Predictions** - Create Kaggle submission\n",
    "5. **Iterative Improvement** - Use 3LC Dashboard to improve data quality\n",
    "\n",
    "### About 3LC (Three Lines of Code)\n",
    "3LC is a data-centric AI platform that enables the **train‚Äìfix‚Äìretrain loop**:\n",
    "- **Train** - Track experiments automatically\n",
    "- **Analyze** - Use Dashboard to find data issues\n",
    "- **Fix** - Correct labels and improve quality\n",
    "- **Retrain** - Iterate with better data\n",
    "\n",
    "**Let's begin!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Environment Setup\n",
    "\n",
    "## Before You Begin\n",
    "\n",
    "This notebook uses **3LC (Three Lines of Code)** for data-centric AI workflows. Follow these steps to set up your environment.\n",
    "\n",
    "### Video Guide\n",
    "Watch the full setup walkthrough: [3LC Quickstart Video](https://www.youtube.com/watch?v=zdIq1QpeSI8&list=PLFOZfHCPrAhDbgmxYcu9Qq5UUVMf7YLFy)\n",
    "\n",
    "---\n",
    "\n",
    "## Step 1: Create a 3LC Account\n",
    "\n",
    "1. Go to [https://account.3lc.ai](https://account.3lc.ai)\n",
    "2. Create your account\n",
    "   - **Note:** A default workspace is automatically created for you (visible after login)\n",
    "   - Your workspace name is what others on your team will see when collaborating\n",
    "3. Get your API key from [https://account.3lc.ai/api-key](https://account.3lc.ai/api-key) and save it for the next step\n",
    "\n",
    "   <div align=\"left\">\n",
    "   <img src=\"content/api.png\" alt=\"Description\" width=\"600\">\n",
    "   </div>\n",
    "\n",
    "---\n",
    "\n",
    "## Step 2: Set Up Python Environment (Recommended)\n",
    "\n",
    "### Create a Virtual Environment\n",
    "\n",
    "**Windows:**\n",
    "```bash\n",
    "python -m venv cotton-weed-env\n",
    "cotton-weed-env\\Scripts\\activate\n",
    "```\n",
    "\n",
    "**Linux/MacOS:**\n",
    "```bash\n",
    "python -m venv cotton-weed-env\n",
    "source cotton-weed-env/bin/activate\n",
    "```\n",
    "\n",
    "**Note:** You can skip this if you prefer to use your current Python environment.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 3: Install 3LC and Dependencies\n",
    "\n",
    "### ‚ö†Ô∏è Important: PyTorch GPU Setup (For GPU Training)\n",
    "\n",
    "The following command will install PyTorch, but **by default it installs the CPU version**. \n",
    "\n",
    "**If you have a GPU and want to use it for training:**\n",
    "1. First, install 3LC: `pip install 3lc-ultralytics`\n",
    "2. Then, **reinstall PyTorch with CUDA support:**\n",
    "   ```bash\n",
    "   # For CUDA 11.8\n",
    "   pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118\n",
    "   \n",
    "   # For CUDA 12.1\n",
    "   pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121\n",
    "   ```\n",
    "   Visit [PyTorch Get Started](https://pytorch.org/get-started/locally/) to find the correct command for your CUDA version.\n",
    "\n",
    "**If you're fine with CPU training (slower but works):**\n",
    "```bash\n",
    "pip install 3lc-ultralytics\n",
    "```\n",
    "\n",
    "**What gets installed:**\n",
    "- `3lc-ultralytics` - 3LC integration with Ultralytics YOLO\n",
    "- `3lc` - Core 3LC library\n",
    "- `ultralytics`, `torch`, `pandas`, `numpy`, `pillow`, `pycocotools`, and other dependencies\n",
    "\n",
    "**System Requirements:**\n",
    "- Python 3.8+ \n",
    "- Windows 10+, Linux, or macOS\n",
    "- GPU with CUDA (optional but recommended for faster training)\n",
    "\n",
    "---\n",
    "\n",
    "## Step 4: Login to 3LC\n",
    "\n",
    "Once Finished with installation in the same terminal login using an API key. [Create one if not present](https://account.3lc.ai/api-key). \n",
    "Replace `<your_api_key>` with your actual API key:\n",
    "\n",
    "```bash\n",
    "3lc login <your_api_key>\n",
    "```\n",
    "\n",
    "This saves your API key locally. **For future sessions, you don't need to run this again.**\n",
    "\n",
    "---\n",
    "\n",
    "## Step 5: Start the 3LC Service (For Dashboard visualization)\n",
    "\n",
    "**Important Clarification:**\n",
    "- The 3LC service is **NOT required for training** - you can train models without it\n",
    "- It **IS required** if you want to use the 3LC Dashboard to visualize and analyze your data/runs\n",
    "- Since the Dashboard is a key part of the data-centric workflow, we recommend starting it\n",
    "\n",
    "**To start the service, run in the terminal:**\n",
    "```bash\n",
    "3lc service\n",
    "```\n",
    "   <div align=\"left\">\n",
    "   <img src=\"content/service.png\" alt=\"Description\" width=\"600\">\n",
    "   </div>\n",
    "\n",
    "**What happens:**\n",
    "- Starts the local service for Dashboard connectivity\n",
    "- Loads some preloaded example projects to help you learn 3LC\n",
    "- These examples are useful for getting familiar with the Dashboard features\n",
    "\n",
    "**Keep this terminal open while using the Dashboard.** To stop: Press `Q` or `Ctrl+C`.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 6: Open 3LC Dashboard (For visualization)\n",
    "\n",
    "Once the service is running, open [https://dashboard.3lc.ai](https://dashboard.3lc.ai) in your browser.\n",
    "\n",
    "**Browser Requirements:**\n",
    "- Chrome (recommended), Firefox, or Edge (latest versions)\n",
    "- Hardware acceleration enabled (GPU) for smoother experience\n",
    "  - Setup guide: [3LC GPU Acceleration Guide](https://docs.3lc.ai/3lc/latest/user-guide/dashboard/gpu-acceleration.html)\n",
    "\n",
    "**Tip:** Explore the preloaded example projects to learn Dashboard features before working on competition data!\n",
    "\n",
    "---\n",
    "\n",
    "## Verification Checklist\n",
    "\n",
    "Before running the notebook, ensure:\n",
    "\n",
    "1. ‚úÖ 3LC account created and API key obtained\n",
    "2. ‚úÖ Python environment activated (if using venv)\n",
    "3. ‚úÖ `3lc-ultralytics` installed\n",
    "4. ‚úÖ PyTorch GPU version installed (if you have a GPU)\n",
    "5. ‚úÖ Logged in to 3LC (`3lc login <api_key>`)\n",
    "6. ‚úÖ 3LC service running and Dashboard open\n",
    "\n",
    "**For future sessions:** Only steps 2 and 6 are needed (activate environment and optionally start service/Dashboard).\n",
    "\n",
    "---\n",
    "\n",
    "## Additional Resources\n",
    "\n",
    "- [3LC Documentation](https://docs.3lc.ai/)\n",
    "- [3LC Example Notebooks](https://github.com/3lc-ai/3lc-examples?tab=readme-ov-file)\n",
    "- [Getting Started Video Playlist](https://www.youtube.com/watch?v=zdIq1QpeSI8&list=PLFOZfHCPrAhDbgmxYcu9Qq5UUVMf7YLFy)\n",
    "\n",
    "---\n",
    "\n",
    "## Troubleshooting\n",
    "\n",
    "**\"3lc: command not found\"**\n",
    "‚Üí Activate your Python environment or reinstall 3lc\n",
    "\n",
    "**\"API key invalid\"**\n",
    "‚Üí Check your API key at [https://account.3lc.ai/api-key](https://account.3lc.ai/api-key)\n",
    "\n",
    "**\"No GPU detected\" during training**\n",
    "‚Üí Reinstall PyTorch with CUDA support (see Step 3)\n",
    "\n",
    "**\"Cannot connect to Dashboard\"**\n",
    "‚Üí Make sure `3lc service` is running in a terminal\n",
    "\n",
    "\n",
    "**Ready? Let's begin!**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Phase 1: Environment Setup & Dataset Registration\n",
    "\n",
    "First, let's verify our environment and register the dataset with 3LC Tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import torch\n",
    "import tlc\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# Check environment\n",
    "print(\"Environment Check:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"3LC version: {tlc.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(\n",
    "        f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\"\n",
    "    )\n",
    "else:\n",
    "    print(\"!!! No GPU detected - training will be slower on CPU\")\n",
    "\n",
    "print(\"\\n All systems ready! Let's begin.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1: Dataset Configuration\n",
    "\n",
    "The competition dataset is organized in YOLO format with train/val/test splits already prepared.\n",
    "\n",
    "### Dataset Structure:\n",
    "```\n",
    "cotton_weed_dataset/\n",
    "‚îú‚îÄ‚îÄ train/images/        # 542 training images\n",
    "‚îú‚îÄ‚îÄ train/labels/        # 542 YOLO label files  \n",
    "‚îú‚îÄ‚îÄ val/images/          # 133 validation images\n",
    "‚îú‚îÄ‚îÄ val/labels/          # 133 YOLO label files\n",
    "‚îú‚îÄ‚îÄ test/images/         # 170 test images (no labels provided)\n",
    "‚îî‚îÄ‚îÄ dataset.yaml         # YOLO dataset configuration\n",
    "```\n",
    "\n",
    "### Test Set Information:\n",
    "The test set contains **170 images** split as follows:\n",
    "- **Public leaderboard**: 85 images (50%)\n",
    "- **Private leaderboard**: 85 images (50%)\n",
    "\n",
    "**Note**: All 170 test images are included in the download for convenience. Only the public/private split determines which images are used for each leaderboard score.\n",
    "\n",
    "### YOLO Label Format:\n",
    "Each `.txt` file contains bounding boxes: `class_id x_center y_center width height`  \n",
    "All coordinates are normalized to [0, 1]\n",
    "\n",
    "### ‚ö†Ô∏è Data Quality Note:\n",
    "This dataset includes labeling imperfections. You'll need to identify and fix these issues to maximize performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up file paths\n",
    "WORK_DIR = Path(\".\")  # Current directory\n",
    "DATASET_YAML = WORK_DIR / \"dataset.yaml\"\n",
    "\n",
    "# Verify paths exist\n",
    "print(\"Verifying dataset structure...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if not DATASET_YAML.exists():\n",
    "    print(f\"Could not find {DATASET_YAML}\")\n",
    "    print(f\"Current directory: {Path.cwd()}\")\n",
    "    print(\"Please make sure dataset.yaml is in the current directory\")\n",
    "    raise FileNotFoundError(f\"Dataset config not found: {DATASET_YAML}\")\n",
    "\n",
    "print(f\"‚úÖ Dataset config: {DATASET_YAML}\")\n",
    "print(f\"‚úÖ Working directory: {WORK_DIR.resolve()}\")\n",
    "\n",
    "# Display dataset configuration\n",
    "print(\"\\n Dataset Configuration:\")\n",
    "print(\"-\" * 50)\n",
    "with open(DATASET_YAML, \"r\") as f:\n",
    "    config_content = f.read()\n",
    "    print(config_content)\n",
    "\n",
    "# Count dataset files\n",
    "train_images = list((WORK_DIR / \"train\" / \"images\").glob(\"*.jpg\"))\n",
    "train_labels = list((WORK_DIR / \"train\" / \"labels\").glob(\"*.txt\"))\n",
    "val_images = list((WORK_DIR / \"val\" / \"images\").glob(\"*.jpg\"))\n",
    "val_labels = list((WORK_DIR / \"val\" / \"labels\").glob(\"*.txt\"))\n",
    "test_images = list((WORK_DIR / \"test\" / \"images\").glob(\"*.jpg\"))\n",
    "\n",
    "print(\"\\n Dataset Statistics:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"‚úÖ Training:   {len(train_images)} images, {len(train_labels)} labels\")\n",
    "print(f\"‚úÖ Validation: {len(val_images)} images, {len(val_labels)} labels\")\n",
    "print(f\"‚úÖ Test: {len(test_images)} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Visual Guide: Target Weed Species\n",
    "\n",
    "Before we dive into model development, let's familiarize ourselves with the three target weed species. Understanding their visual characteristics is crucial for effective model training and data quality assessment.\n",
    "\n",
    "### üåø The Three Target Weeds:\n",
    "\n",
    "**Class 0: Carpetweed (*Mollugo verticillata*)**\n",
    "- Mat-forming low-growing weed\n",
    "- Small, spoon-shaped leaves arranged in whorls\n",
    "- Forms dense ground cover competing with cotton seedlings\n",
    "- Light green color, spreads horizontally\n",
    "\n",
    "**Class 1: Morning Glory (*Ipomoea* species)**\n",
    "- Climbing/twining vine that wraps around cotton plants\n",
    "- Heart-shaped or lobed leaves\n",
    "- Major yield impact - strangles cotton plants\n",
    "- Can have purple, white, or pink flowers\n",
    "\n",
    "**Class 2: Palmer Amaranth (*Amaranthus palmeri*)**\n",
    "- Tall, upright, fast-growing \"super weed\"\n",
    "- Lance-shaped leaves with prominent veins\n",
    "- Herbicide-resistant strain causing major agricultural problems\n",
    "- Reddish stems, can grow several feet tall\n",
    "\n",
    "**Why Visual Familiarity Matters:**\n",
    "- Helps identify mislabeled samples during error analysis\n",
    "- Enables better understanding of class confusion patterns\n",
    "- Assists in recognizing missing annotations\n",
    "- Improves data quality decisions in the train-fix-retrain loop\n",
    "\n",
    "Let's view example images from our dataset to see what these weeds actually look like!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example images for each weed class\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "print(\"Finding example images for each weed class...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Set up paths\n",
    "TRAIN_IMAGES = WORK_DIR / \"train\" / \"images\"\n",
    "TRAIN_LABELS = WORK_DIR / \"train\" / \"labels\"\n",
    "CLASS_NAMES = [\"Carpetweed\", \"Morning Glory\", \"Palmer Amaranth\"]\n",
    "\n",
    "# Find images containing each class\n",
    "class_examples = defaultdict(list)\n",
    "\n",
    "for label_file in TRAIN_LABELS.glob(\"*.txt\"):\n",
    "    if label_file.stat().st_size > 0:\n",
    "        with open(label_file, \"r\") as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) >= 5:\n",
    "                    class_id = int(parts[0])\n",
    "                    image_file = TRAIN_IMAGES / f\"{label_file.stem}.jpg\"\n",
    "                    if image_file.exists():\n",
    "                        class_examples[class_id].append(image_file)\n",
    "\n",
    "# Select one clear example per class (first occurrence)\n",
    "examples_to_show = {}\n",
    "for class_id in range(len(CLASS_NAMES)):\n",
    "    if class_examples[class_id]:\n",
    "        examples_to_show[class_id] = class_examples[class_id][0]\n",
    "        print(\n",
    "            f\"‚úì Found example for {CLASS_NAMES[class_id]}: {examples_to_show[class_id].name}\"\n",
    "        )\n",
    "    else:\n",
    "        print(f\"!!!  No examples found for {CLASS_NAMES[class_id]}\")\n",
    "\n",
    "# Display the examples\n",
    "if examples_to_show:\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"Displaying example images with bounding boxes...\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    fig, axes = plt.subplots(1, len(examples_to_show), figsize=(15, 5))\n",
    "    if len(examples_to_show) == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    colors = [(0, 255, 0), (255, 0, 0), (0, 0, 255)]  # BGR colors for OpenCV\n",
    "\n",
    "    for idx, (class_id, image_path) in enumerate(sorted(examples_to_show.items())):\n",
    "        # Read image\n",
    "        img = cv2.imread(str(image_path))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        h, w = img.shape[:2]\n",
    "\n",
    "        # Read corresponding label\n",
    "        label_file = TRAIN_LABELS / f\"{image_path.stem}.txt\"\n",
    "        with open(label_file, \"r\") as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) >= 5:\n",
    "                    cls = int(parts[0])\n",
    "                    if cls == class_id:  # Only draw boxes for the target class\n",
    "                        # Convert YOLO format to pixel coordinates\n",
    "                        x_center, y_center, box_w, box_h = map(float, parts[1:5])\n",
    "                        x1 = int((x_center - box_w / 2) * w)\n",
    "                        y1 = int((y_center - box_h / 2) * h)\n",
    "                        x2 = int((x_center + box_w / 2) * w)\n",
    "                        y2 = int((y_center + box_h / 2) * h)\n",
    "\n",
    "                        # Draw bounding box\n",
    "                        color = colors[class_id]\n",
    "                        cv2.rectangle(img, (x1, y1), (x2, y2), color, 3)\n",
    "\n",
    "                        # Add class label\n",
    "                        label_text = f\"{CLASS_NAMES[class_id]}\"\n",
    "                        cv2.putText(\n",
    "                            img,\n",
    "                            label_text,\n",
    "                            (x1, y1 - 10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                            0.8,\n",
    "                            color,\n",
    "                            2,\n",
    "                        )\n",
    "\n",
    "        # Display\n",
    "        axes[idx].imshow(img)\n",
    "        axes[idx].set_title(\n",
    "            f\"Class {class_id}: {CLASS_NAMES[class_id]}\", fontsize=12, fontweight=\"bold\"\n",
    "        )\n",
    "        axes[idx].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\n‚úÖ Example images displayed!\")\n",
    "    print(\"\\n Pro Tip: Keep these visual characteristics in mind when:\")\n",
    "    print(\"   ‚Ä¢ Analyzing model predictions in the 3LC Dashboard\")\n",
    "    print(\"   ‚Ä¢ Identifying mislabeled or missing annotations\")\n",
    "    print(\"   ‚Ä¢ Understanding class confusion patterns\")\n",
    "\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  Could not find example images for visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2: Introduction to 3LC - Data-Centric AI Platform\n",
    "\n",
    "### What is 3LC?\n",
    "**3LC (Three Lines of Code)** is your toolkit for data-centric AI. It enables the critical **train‚Äìfix‚Äìretrain loop**:\n",
    "\n",
    "#### üìä Tables - Dataset Registration & Analysis\n",
    "- Register your datasets with structured metadata\n",
    "- Automatic quality analysis and statistics\n",
    "- Visual exploration in browser dashboard\n",
    "- Track data versions and changes\n",
    "\n",
    "#### üèÉ Runs - Experiment Tracking & Model Feedback\n",
    "- Automatically track all training experiments\n",
    "- **Analyze model errors to identify data problems**\n",
    "- Compare runs to find what actually improves performance\n",
    "- Export predictions for detailed failure analysis\n",
    "\n",
    "### The Train‚ÄìFix‚ÄìRetrain Workflow\n",
    "\n",
    "**Traditional Approach (Doesn't Work Here):**\n",
    "- ‚ùå Train bigger models ‚Üí **Not allowed (hardware constraints)**\n",
    "- ‚ùå Ensemble multiple models ‚Üí **Prohibited by rules**\n",
    "- ‚ùå Use Test-Time Augmentation (TTA) ‚Üí **Prohibited (slows inference and violates edge device constraints)**\n",
    "\n",
    "**Data-Centric Approach (The Solution):**\n",
    "1. ‚úÖ **Train** baseline model with 3LC Run tracking\n",
    "2. ‚úÖ **Analyze** errors using 3LC Dashboard  \n",
    "3. ‚úÖ **Fix** data issues (labels, annotations, missing weeds)\n",
    "4. ‚úÖ **Retrain** with improved data\n",
    "5. ‚úÖ **Repeat** - Continuous improvement loop\n",
    "\n",
    "### Why This Matters\n",
    "In production AI, model feedback reveals data problems you'd never find manually. 3LC makes this systematic and reproducible - exactly how production teams work.\n",
    "\n",
    "**This is the core skill of this competition!** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3: Register Your Dataset with 3LC\n",
    "\n",
    "Now we'll register your dataset with 3LC, creating **Tables** that track your data.\n",
    "\n",
    "### What's a 3LC Table?\n",
    "A Table is like a smart spreadsheet for your dataset - it tracks images, labels, and metadata, enabling:\n",
    "- Visual exploration in the Dashboard\n",
    "- Data versioning (track edits over time)\n",
    "- Integration with training for automatic error analysis\n",
    "\n",
    "**‚ö†Ô∏è Important:** Run the cell below **only once** to register your dataset. After that, you can skip it when retraining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Create 3LC Tables from YOLO Format Dataset\n",
    "# ‚ö†Ô∏è RUN THIS CELL ONLY ONCE (Initial Setup)\n",
    "# ============================================================================\n",
    "# This cell registers your dataset with 3LC for version control and analysis.\n",
    "#\n",
    "# ‚ö†Ô∏è IMPORTANT FOR RETRAINING:\n",
    "#    - First time: Run this cell to create tables\n",
    "#    - Retraining: SKIP this cell and go directly to the next cell\n",
    "#                  (it loads tables independently without needing this)\n",
    "\n",
    "# Import required packages\n",
    "import tlc\n",
    "from pathlib import Path\n",
    "\n",
    "# Define constants for 3LC registration\n",
    "PROJECT_NAME = \"kaggle_cotton_weed_detection\"\n",
    "DATASET_NAME = \"cotton_weed_det3\"\n",
    "WORK_DIR = Path(\".\")\n",
    "DATASET_YAML = WORK_DIR / \"dataset.yaml\"\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"DATA REGISTRATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ============================================================================\n",
    "# IDEMPOTENCY CHECK - Safe to run multiple times\n",
    "# ============================================================================\n",
    "try:\n",
    "    # Check if tables already exist\n",
    "    existing_train = tlc.Table.from_names(\n",
    "        project_name=PROJECT_NAME,\n",
    "        dataset_name=DATASET_NAME,\n",
    "        table_name=f\"{DATASET_NAME}-train1\",\n",
    "    )\n",
    "    existing_val = tlc.Table.from_names(\n",
    "        project_name=PROJECT_NAME,\n",
    "        dataset_name=DATASET_NAME,\n",
    "        table_name=f\"{DATASET_NAME}-val1\",\n",
    "    )\n",
    "\n",
    "    print(\"\\n‚ö†Ô∏è  Tables already exist!\")\n",
    "    print(f\" Training: {len(existing_train)} samples\")\n",
    "    print(f\" Validation: {len(existing_val)} samples\")\n",
    "    print(\"\\n‚úÖ Using existing tables (no duplicates created)\")\n",
    "    print(\" This cell is safe to run multiple times!\")\n",
    "\n",
    "    # Set variables for compatibility\n",
    "    train_table = existing_train\n",
    "    val_table = existing_val\n",
    "\n",
    "except Exception:\n",
    "    # Tables don't exist, create them\n",
    "    print(\"\\n‚úÖ No existing tables - creating new ones...\")\n",
    "\n",
    "    # Create training table\n",
    "    print(\"\\n Creating training table...\")\n",
    "    train_table = tlc.Table.from_yolo(\n",
    "        dataset_yaml_file=str(DATASET_YAML),\n",
    "        split=\"train\",\n",
    "        task=\"detect\",\n",
    "        dataset_name=DATASET_NAME,\n",
    "        project_name=PROJECT_NAME,\n",
    "        table_name=f\"{DATASET_NAME}-train1\",\n",
    "    )\n",
    "\n",
    "    # Create validation table\n",
    "    print(\" Creating validation table...\")\n",
    "    val_table = tlc.Table.from_yolo(\n",
    "        dataset_yaml_file=str(DATASET_YAML),\n",
    "        split=\"val\",\n",
    "        task=\"detect\",\n",
    "        dataset_name=DATASET_NAME,\n",
    "        project_name=PROJECT_NAME,\n",
    "        table_name=f\"{DATASET_NAME}-val1\",\n",
    "    )\n",
    "\n",
    "# Display registration results\n",
    "print(\"\\n‚úÖ Tables created successfully!\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\n Training Table:\")\n",
    "print(f\"   Samples: {len(train_table)}\")\n",
    "print(f\"   URL: {train_table.url}\")\n",
    "\n",
    "print(\"\\n Validation Table:\")\n",
    "print(f\"   Samples: {len(val_table)}\")\n",
    "print(f\"   URL: {val_table.url}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚úÖ Phase 1 Complete: Dataset Registered with 3LC!\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\n Next Steps:\")\n",
    "print(\"  (Optional) Explore tables in Dashboard: https://dashboard.3lc.ai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Explore Your Data in the Dashboard \n",
    "\n",
    "Before training, you can explore your dataset visually:\n",
    "\n",
    "1. Open Dashboard: [https://dashboard.3lc.ai](https://dashboard.3lc.ai)\n",
    "2. Navigate to your project: `kaggle_cotton_weed_detection`\n",
    "3. Click on a table to view images, annotations, and statistics\n",
    "4. To view bounding box overlay on your images click on the `IMAGE` column and ctrl click `BBOX` columns and press `2`. Output will be a 2D chart omething like this:\n",
    "\n",
    "<div align=\"left\">\n",
    "  <img src=\"content/dashboard.png\" alt=\"Description\" width=\"600\">\n",
    "</div>\n",
    "\n",
    "**This is optional during the first iteration** - you can skip ahead to training and come back to the Dashboard later for error analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4: Train Your Baseline Model\n",
    "\n",
    "Time to train your first model! We'll use YOLOv8n with 3LC tracking.\n",
    "\n",
    "**The workflow:**\n",
    "1. **Load tables** - Get your registered data \n",
    "\n",
    "    1.1 To Load tables Via Urls go to the Tables tab and copy to table URL to clipboard by hovering over the table and clicking this icon in the url column shown in the screenshot below:\n",
    "![3LC Dashboard](content/table_url.png)\n",
    "\n",
    "\n",
    "2. **Configure training** - Set epochs, batch size, run name\n",
    "3. **Train** - YOLOv8n trains with automatic tracking\n",
    "\n",
    "**For retraining later:** Just rerun the training cells below. They automatically load the latest table version (including any edits you make in the Dashboard).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Competition Rules Reminder:\n",
    "- ‚úÖ **YOLOv8n only** (3M parameters, 6MB)\n",
    "- ‚úÖ **640 input size** (fixed)\n",
    "- ‚úÖ **No ensembles**\n",
    "- ‚úÖ **Hyperparameter tuning allowed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Load Tables + Configure Training\n",
    "# ============================================================================\n",
    "# This cell:\n",
    "#   1. Loads your registered tables (includes any Dashboard edits)\n",
    "#   2. Sets up training configuration (RUN_NAME, EPOCHS, etc.)\n",
    "#\n",
    "# For retraining: Just modify RUN_NAME/EPOCHS and rerun this + next cell!\n",
    "\n",
    "# Import required packages\n",
    "import tlc\n",
    "from tlc_ultralytics import YOLO, Settings\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 1: Load Tables for Training\n",
    "# ============================================================================\n",
    "# Define 3LC project constants\n",
    "PROJECT_NAME = \"kaggle_cotton_weed_detection\"\n",
    "DATASET_NAME = \"cotton_weed_det3\"\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"LOADING TABLES FOR TRAINING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "try:\n",
    "    # ========================================================================\n",
    "    # OPTION 1: Load by Name (Recommended - Automatic Latest Version)\n",
    "    # ========================================================================\n",
    "    # This automatically loads the latest table version (includes Dashboard edits)\n",
    "\n",
    "    train_table_latest = tlc.Table.from_names(\n",
    "        project_name=PROJECT_NAME,\n",
    "        dataset_name=DATASET_NAME,\n",
    "        table_name=f\"{DATASET_NAME}-train1\",\n",
    "    ).latest()\n",
    "\n",
    "    val_table_latest = tlc.Table.from_names(\n",
    "        project_name=PROJECT_NAME,\n",
    "        dataset_name=DATASET_NAME,\n",
    "        table_name=f\"{DATASET_NAME}-val1\",\n",
    "    ).latest()\n",
    "\n",
    "    print(\n",
    "        f\"\\n‚úÖ Training table loaded: {len(train_table_latest)} samples (latest version)\"\n",
    "    )\n",
    "    print(\n",
    "        f\"‚úÖ Validation table loaded: {len(val_table_latest)} samples (latest version)\"\n",
    "    )\n",
    "\n",
    "    # Prepare tables dictionary for training\n",
    "    tables = {\"train\": train_table_latest, \"val\": val_table_latest}\n",
    "\n",
    "    # ========================================================================\n",
    "    # OPTION 2: Load by URL (Alternative - Specific Table Version)\n",
    "    # ========================================================================\n",
    "    # Comment above and Uncomment below to load specific table URLs from Dashboard instead\n",
    "    # Use this when you want a specific edited table version, not the latest\n",
    "\n",
    "    \"\"\"\n",
    "    # Get URLs from Dashboard: Click on the Tables tab ‚Üí Copy URL from the spoecific table info panel to clipboard\n",
    "    TRAIN_TABLE_URL = \"paste_your_train_table_url_here\"\n",
    "    VAL_TABLE_URL = \"paste_your_val_table_url_here\"\n",
    "    \n",
    "    train_table_latest = tlc.Table.from_url(TRAIN_TABLE_URL)\n",
    "    val_table_latest = tlc.Table.from_url(VAL_TABLE_URL)\n",
    "    \n",
    "    tables = {\"train\": train_table_latest, \"val\": val_table_latest}\n",
    "    \n",
    "    print(f\"\\n‚úÖ Training table loaded from URL: {len(tables['train'])} samples\")\n",
    "    print(f\"‚úÖ Validation table loaded from URL: {len(tables['val'])} samples\")\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"‚úÖ Tables Ready!\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n Error loading tables: {e}\")\n",
    "    print(\"\\nüí° Troubleshooting:\")\n",
    "    print(\"   1. Make sure you ran Data Registration Cell at least once\")\n",
    "    print(\"   2. Check that PROJECT_NAME and DATASET_NAME match your setup\")\n",
    "    print(\"   3. Verify tables exist in Dashboard: https://dashboard.3lc.ai\")\n",
    "    raise\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 2: Training Configuration\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"YOLOV8N TRAINING WITH 3LC TRACKING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ============================================================================\n",
    "# TRAINING CONSTANTS - Change these for each iteration\n",
    "# ============================================================================\n",
    "RUN_NAME = \"yolov8n_baseline\"  # Change for each run (e.g., \"v2_fixed_labels\")\n",
    "RUN_DESCRIPTION = \"Baseline YOLOv8n with default hyperparameters\"\n",
    "\n",
    "# Hyperparameters (customize these!)\n",
    "EPOCHS = 5  # Number of training epochs\n",
    "BATCH_SIZE = 16  # Batch size (adjust based on GPU memory)\n",
    "IMAGE_SIZE = 640  # Input image size (FIXED by competition rules)\n",
    "DEVICE = 0  # GPU device (0 for first GPU, 'cpu' for CPU)\n",
    "WORKERS = 4  # Number of dataloader workers\n",
    "\n",
    "# Display configuration\n",
    "print(\"\\n Training Configuration:\")\n",
    "print(f\"   Run name: {RUN_NAME}\")\n",
    "print(\"   Model: YOLOv8n (ONLY model allowed)\")\n",
    "print(f\"   Epochs: {EPOCHS}\")\n",
    "print(f\"   Batch size: {BATCH_SIZE}\")\n",
    "print(f\"   Image size: {IMAGE_SIZE} (FIXED)\")\n",
    "print(f\"   Device: GPU {DEVICE}\" if DEVICE != \"cpu\" else \"   Device: CPU\")\n",
    "\n",
    "# Display dataset info (already loaded in STEP 1 above)\n",
    "print(\"\\n Dataset:\")\n",
    "print(f\"   Training: {len(tables['train'])} samples\")\n",
    "print(f\"   Validation: {len(tables['val'])} samples\")\n",
    "\n",
    "# Create 3LC Settings for run tracking\n",
    "settings = Settings(\n",
    "    project_name=PROJECT_NAME,\n",
    "    run_name=RUN_NAME,\n",
    "    run_description=RUN_DESCRIPTION,\n",
    "    image_embeddings_dim=2,\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚úÖ CONFIGURATION COMPLETE!\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nüí° Configuration Summary:\")\n",
    "print(f\"   ‚Ä¢ Tables loaded: {len(tables['train'])} train, {len(tables['val'])} val\")\n",
    "print(f\"   ‚Ä¢ Run name: {RUN_NAME}\")\n",
    "print(f\"   ‚Ä¢ Training for: {EPOCHS} epochs\")\n",
    "print(f\"   ‚Ä¢ Batch size: {BATCH_SIZE}\")\n",
    "print(f\"   ‚Ä¢ Device: GPU {DEVICE}\" if DEVICE != \"cpu\" else \"   ‚Ä¢ Device: CPU\")\n",
    "\n",
    "print(\"\\n Next: Run the cell below to start training!\")\n",
    "print(\"   (Review the configuration above before proceeding)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Train the Model\n",
    "# ============================================================================\n",
    "# This cell loads YOLOv8n and starts training.\n",
    "# Make sure you ran the cell above first!\n",
    "\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"STARTING TRAINING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Load YOLOv8n pretrained model\n",
    "print(\"\\nLoading YOLOv8n pretrained weights...\")\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "print(\"‚úÖ Model loaded (3M parameters, 6MB size)\")\n",
    "\n",
    "# Train the model with 3LC tracking\n",
    "print(\"\\n Training in progress...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "results = model.train(\n",
    "    tables=tables,  # Use 3LC Tables\n",
    "    name=RUN_NAME,  # Name for saving results (creates runs/detect/{RUN_NAME}/)\n",
    "    epochs=EPOCHS,\n",
    "    imgsz=IMAGE_SIZE,\n",
    "    batch=BATCH_SIZE,\n",
    "    device=DEVICE,\n",
    "    workers=WORKERS,\n",
    "    settings=settings,  # 3LC tracking\n",
    "    val=True,  # Validate during training\n",
    "    # AUGMENTATION - Uncomment for better performance in later iterations:\n",
    "    # mosaic=1.0,              # Mosaic augmentation - helps with scale variation\n",
    "    # copy_paste=0.1,          # Copy-paste - helps with occlusion\n",
    "    # mixup=0.05,              # Mixup - improves generalization\n",
    "    # patience=20,             # Early stopping patience\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚úÖ TRAINING COMPLETE!\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nüìÅ Model Weights Saved:\")\n",
    "print(f\"   Best model: runs/detect/{RUN_NAME}/weights/best.pt\")\n",
    "print(f\"   Last model: runs/detect/{RUN_NAME}/weights/last.pt\")\n",
    "print(\"\\n Use 'best.pt' for predictions and submissions (highest validation mAP)\")\n",
    "\n",
    "print(\"\\n Next Steps:\")\n",
    "print(\"   1. Visit 3LC Dashboard: https://dashboard.3lc.ai/\")\n",
    "print(\"   2. Open your Run to analyze model errors\")\n",
    "print(\"   3. Identify data issues:\")\n",
    "print(\"      ‚Ä¢ False negatives (missed detections)\")\n",
    "print(\"      ‚Ä¢ False positives (incorrect predictions)\")\n",
    "print(\"      ‚Ä¢ Class confusion\")\n",
    "print(\"      ‚Ä¢ Poor localization\")\n",
    "print(\"   4. Fix data issues in Dashboard\")\n",
    "print(\"   5. Retrain with improved data!\")\n",
    "print(\n",
    "    \"\\nLearn more: https://docs.3lc.ai/3lc/latest/how-to/basics/open-project-table-run.html\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## What's Next? The Improvement Loop\n",
    "\n",
    "**Congratulations!** Your baseline model is trained. Now comes the data-centric improvement cycle:\n",
    "\n",
    "1. **Analyze** - Open Dashboard ([https://dashboard.3lc.ai/](https://dashboard.3lc.ai/)) to see your training run and identify errors\n",
    "2. **Fix** - Edit problematic samples directly in Dashboard (fix labels, remove bad images)\n",
    "3. **Retrain** - Rerun the two cells above - they automatically load your edits\n",
    "4. **Compare** - Check if your mAP improved\n",
    "5. **Repeat** - Keep iterating!\n",
    "\n",
    "**üí° Tip:** Each time you edit data in the Dashboard, just rerun the training cells. The `.latest()` method automatically picks up your changes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 5.5: Load Model Weights (Optional)\n",
    "\n",
    "**IMPORTANT:** This cell allows you to load trained weights instead of using the model from the previous training session.\n",
    "\n",
    "### When to use this:\n",
    "- ‚úÖ Loading a previously trained model from the `runs` folder\n",
    "- ‚úÖ Continuing work in a new notebook session\n",
    "- ‚úÖ Testing predictions from your best training run\n",
    "- ‚úÖ Comparing different model versions\n",
    "\n",
    "### Options:\n",
    "1. **Use current model**: Skip this cell if you just trained a model above\n",
    "2. **Load latest weights**: Automatically finds the most recent training run\n",
    "3. **Load specific weights**: Provide a custom path to your best model\n",
    "\n",
    "### Where are model weights saved?\n",
    "After training, YOLOv8 saves weights in:\n",
    "```\n",
    "runs/detect/train/weights/\n",
    "‚îú‚îÄ‚îÄ best.pt      # Best checkpoint (highest mAP)\n",
    "‚îî‚îÄ‚îÄ last.pt      # Last epoch checkpoint\n",
    "```\n",
    "\n",
    "**Pro tip:** Always use `best.pt` for final submissions!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# OPTIONAL: Load Model Weights from Previous Training\n",
    "# ============================================================================\n",
    "# Uncomment ONE of the options below to load weights\n",
    "\n",
    "# OPTION 1: Use the model from the training cell above (DEFAULT)\n",
    "# If you just ran the training cell, the 'model' variable is already loaded\n",
    "# ‚Üí No action needed, skip this cell!\n",
    "\"\"\"\n",
    "print(\"Current model status:\")\n",
    "try:\n",
    "    print(f\"‚úÖ Model loaded: {type(model).__name__}\")\n",
    "    print(f\"  Using model from training session above\")\n",
    "except NameError:\n",
    "    print(\"  No model found from training session\")\n",
    "    print(\"  You must load weights using one of the options below!\")\n",
    "\"\"\"\n",
    "# OPTION 2: Load the LATEST trained model from runs folder\n",
    "# Uncomment the ENTIRE block below to auto-load the most recent training run\n",
    "\n",
    "\"\"\"\n",
    "from tlc_ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "\n",
    "# Find the most recent training run\n",
    "runs_dir = Path(\"runs/detect\")\n",
    "if runs_dir.exists():\n",
    "    train_dirs = sorted(runs_dir.glob(\"train*\"), key=lambda x: x.stat().st_mtime, reverse=True)\n",
    "    if train_dirs:\n",
    "        latest_weights = train_dirs[0] / \"weights\" / \"best.pt\"\n",
    "        if latest_weights.exists():\n",
    "            print(f\"\\nLoading latest model: {latest_weights}\")\n",
    "            print(f\"Using weights from Ultralytics run folder: {train_dirs[0]}\")\n",
    "            model = YOLO(str(latest_weights))\n",
    "            print(\"‚úÖ Model loaded successfully!\")\n",
    "        else:\n",
    "            print(f\"!!! Weights not found: {latest_weights}\")\n",
    "    else:\n",
    "        print(\"!!! No training runs found in runs/detect/\")\n",
    "else:\n",
    "    print(\"!!! runs/detect/ directory not found\")\n",
    "\"\"\"\n",
    "\n",
    "# By default, use the model from Cell 11 (training)\n",
    "print(\"‚úì Using model from Cell 11 training session\")\n",
    "print(\"  (To load different weights, uncomment one of the options above)\")\n",
    "\n",
    "\n",
    "# OPTION 3: Load SPECIFIC weights (custom path)\n",
    "# Replace the path with your best model\n",
    "\"\"\"\n",
    "from tlc_ultralytics import YOLO\n",
    "\n",
    "# Example paths:\n",
    "# - \"runs/detect/train/weights/best.pt\"           # First training run\n",
    "# - \"runs/detect/train2/weights/best.pt\"          # Second training run\n",
    "# - \"runs/detect/yolov8n_v3/weights/best.pt\"      # Named run\n",
    "\n",
    "CUSTOM_WEIGHTS_PATH = \"runs/detect/train/weights/best.pt\"\n",
    "\n",
    "print(f\"\\nLoading custom weights: {CUSTOM_WEIGHTS_PATH}\")\n",
    "model = YOLO(CUSTOM_WEIGHTS_PATH)\n",
    "print(\"‚úÖ Model loaded successfully!\")\n",
    "\"\"\"\n",
    "\n",
    "# OPTION 4: Load pretrained YOLOv8n (no custom training)\n",
    "# Use this if you want to test the baseline pretrained model\n",
    "\"\"\"\n",
    "from tlc_ultralytics import YOLO\n",
    "\n",
    "print(\"\\nLoading pretrained YOLOv8n (COCO weights)\")\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "print(\"‚úÖ Model loaded successfully!\")\n",
    "print(\"!!!  Note: This is the pretrained model, not trained on cotton weeds!\")\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Ready to generate predictions!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 6: Generate Test Predictions\n",
    "\n",
    "Generate predictions on the test set for Kaggle submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "# Define paths and constants\n",
    "WORK_DIR = Path(\".\")\n",
    "TEST_DIR = WORK_DIR / \"test\" / \"images\"\n",
    "PRED_DIR = Path(\"predictions\")\n",
    "IMAGE_SIZE = 640  # Competition requirement\n",
    "\n",
    "# Get list of test images\n",
    "test_images = list(TEST_DIR.glob(\"*.jpg\"))\n",
    "\n",
    "# ============================================================================\n",
    "# SAFER FILE MANAGEMENT - Backup instead of delete\n",
    "# ============================================================================\n",
    "if PRED_DIR.exists():\n",
    "    from datetime import datetime\n",
    "\n",
    "    # Create timestamped backup instead of deleting\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    backup_dir = Path(f\"predictions_backup_{timestamp}\")\n",
    "\n",
    "    print(\"‚ö†Ô∏è  Predictions folder exists. Creating backup...\")\n",
    "    print(f\"   Moving to: {backup_dir}\")\n",
    "\n",
    "    shutil.move(str(PRED_DIR), str(backup_dir))\n",
    "\n",
    "    print(f\"‚úÖ Previous predictions backed up: {backup_dir}\")\n",
    "    print(\"   (Delete old backups manually if not needed)\")\n",
    "else:\n",
    "    print(\"‚úÖ No existing predictions found\")\n",
    "\n",
    "print(\"Generating predictions on test set...\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Test images: {TEST_DIR}\")\n",
    "print(f\"Output directory: {PRED_DIR}\")\n",
    "print(f\"Test set size: {len(test_images)} images\")\n",
    "\n",
    "# Run inference\n",
    "print(\"\\nRunning inference...\")\n",
    "test_results = model.predict(\n",
    "    source=str(TEST_DIR),\n",
    "    save=False,  # Don't save annotated images (faster, prevents duplication)\n",
    "    save_txt=True,  # Save YOLO format predictions\n",
    "    save_conf=True,  # Include confidence scores\n",
    "    conf=0,  # Confidence threshold (adjust as needed)\n",
    "    imgsz=IMAGE_SIZE,\n",
    "    project=str(PRED_DIR.parent),\n",
    "    name=PRED_DIR.name,\n",
    "    exist_ok=False,  # Don't allow overwriting (ensures clean predictions)\n",
    ")\n",
    "\n",
    "print(\"\\n----Predictions generated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 7: Analyze Test Predictions (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "from pathlib import Path\n",
    "\n",
    "# Define constants\n",
    "CLASS_NAMES = [\"Carpetweed\", \"Morning Glory\", \"Palmer Amaranth\"]\n",
    "\n",
    "# Analyze predictions\n",
    "PRED_DIR = Path(\"predictions\")  # Must match Cell 21\n",
    "labels_dir = PRED_DIR / \"labels\"\n",
    "\n",
    "if labels_dir.exists():\n",
    "    print(\"Test Set Prediction Analysis:\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    pred_files = list(labels_dir.glob(\"*.txt\"))\n",
    "\n",
    "    class_counts = {i: 0 for i in range(len(CLASS_NAMES))}\n",
    "    images_with_preds = 0\n",
    "    total_detections = 0\n",
    "\n",
    "    for pred_file in pred_files:\n",
    "        if pred_file.stat().st_size > 0:\n",
    "            images_with_preds += 1\n",
    "            with open(pred_file, \"r\") as f:\n",
    "                for line in f:\n",
    "                    if line.strip():\n",
    "                        parts = line.strip().split()\n",
    "                        if len(parts) >= 6:\n",
    "                            class_id = int(parts[0])\n",
    "                            class_counts[class_id] += 1\n",
    "                            total_detections += 1\n",
    "\n",
    "    print(f\"Total test images: {len(test_images)}\")\n",
    "    print(f\"Images with detections: {images_with_preds}\")\n",
    "    print(f\"Images with no detections: {len(test_images) - images_with_preds}\")\n",
    "    print(f\"Total detections: {total_detections}\")\n",
    "\n",
    "    print(\"\\n Detections by class:\")\n",
    "    for class_id, count in class_counts.items():\n",
    "        percentage = (count / total_detections * 100) if total_detections > 0 else 0\n",
    "        print(f\"   {CLASS_NAMES[class_id]:20s}: {count:4d} ({percentage:5.1f}%)\")\n",
    "\n",
    "    print(\"\\n----Analysis complete!\")\n",
    "else:\n",
    "    print(\"!!!!No predictions found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 8: Convert to Kaggle Submission Format (Required)\n",
    "\n",
    "Convert YOLO predictions to Kaggle CSV format.\n",
    "\n",
    "### ‚úÖ Submission Format Requirements:\n",
    "**IMPORTANT:** Use exact column names and format below!\n",
    "\n",
    "**Columns:** `image_id,prediction_string` (lowercase!)\n",
    "\n",
    "**Prediction String Format:**\n",
    "- Each box: `class_id confidence x_center y_center width height` (6 values, space-separated)\n",
    "  - `class_id`: 0 (carpetweed), 1 (morningglory), 2 (palmer_amaranth)\n",
    "  - `confidence`: 0.0-1.0 (model confidence score)\n",
    "  - `x_center, y_center, width, height`: normalized coordinates (0-1)\n",
    "- Multiple boxes: Space-separated on same line\n",
    "- No detections: Use `\"no box\"` (not empty string!)\n",
    "\n",
    "### Example:\n",
    "```csv\n",
    "image_id,prediction_string\n",
    "img_001,1 0.95 0.5 0.5 0.2 0.3 2 0.87 0.7 0.4 0.15 0.2\n",
    "img_002,no box\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 8: Generate Kaggle Submission By running this cell of code\n",
    "# ============================================================================\n",
    "# Import required packages\n",
    "from pathlib import Path\n",
    "\n",
    "# Define paths\n",
    "WORK_DIR = Path(\".\")  # Current directory\n",
    "PRED_DIR = Path(\n",
    "    \"predictions\"\n",
    ")  # Prediction directory (change path if you want to convert from a different predictions folder)\n",
    "TEST_DIR = (\n",
    "    WORK_DIR / \"test\" / \"images\"\n",
    ")  # Change path if you have the Test images stored Elsewhere\n",
    "\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"GENERATING KAGGLE SUBMISSION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "labels_dir = PRED_DIR / \"labels\"\n",
    "output_csv = \"submission.csv\"\n",
    "\n",
    "# Get all test images (deduplicate by stem to avoid duplicates from case-insensitive file systems)\n",
    "test_images_dict = {}  # Use dict to automatically deduplicate by image_id (stem)\n",
    "for ext in [\"*.jpg\", \"*.jpeg\", \"*.JPG\", \"*.JPEG\", \"*.png\", \"*.PNG\"]:\n",
    "    for img_path in TEST_DIR.glob(ext):\n",
    "        image_id = img_path.stem  # filename without extension\n",
    "        if image_id not in test_images_dict:\n",
    "            test_images_dict[image_id] = img_path\n",
    "\n",
    "# Convert to sorted list\n",
    "test_images_list = [\n",
    "    test_images_dict[img_id] for img_id in sorted(test_images_dict.keys())\n",
    "]\n",
    "\n",
    "print(f\"\\n‚úì Found {len(test_images_list)} test images\")\n",
    "print(f\"‚úì Looking for predictions in: {labels_dir}\")\n",
    "\n",
    "# Create submission data\n",
    "submission_data = []\n",
    "images_with_preds = 0\n",
    "images_without_preds = 0\n",
    "total_boxes = 0\n",
    "\n",
    "for img_path in test_images_list:\n",
    "    image_id = img_path.stem\n",
    "    pred_file = labels_dir / f\"{image_id}.txt\"\n",
    "\n",
    "    # Check if prediction file exists and has content\n",
    "    if pred_file.exists() and pred_file.stat().st_size > 0:\n",
    "        prediction_boxes = []\n",
    "\n",
    "        with open(pred_file, \"r\") as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if line:\n",
    "                    parts = line.split()\n",
    "\n",
    "                    # YOLO saves as: class xc yc w h conf (confidence is LAST!)\n",
    "                    # Kaggle needs: class conf xc yc w h (confidence is SECOND!)\n",
    "                    if len(parts) >= 6:\n",
    "                        # Reorder values: move confidence from position 5 to position 1\n",
    "                        class_id = parts[0]\n",
    "                        conf = parts[5]  # Confidence is at the end in YOLO format\n",
    "                        xc, yc, w, h = parts[1], parts[2], parts[3], parts[4]\n",
    "                        box_str = f\"{class_id} {conf} {xc} {yc} {w} {h}\"\n",
    "                        prediction_boxes.append(box_str)\n",
    "                        total_boxes += 1\n",
    "\n",
    "        if prediction_boxes:\n",
    "            # Join all boxes with spaces\n",
    "            prediction_string = \" \".join(prediction_boxes)\n",
    "            images_with_preds += 1\n",
    "        else:\n",
    "            prediction_string = \"no box\"\n",
    "            images_without_preds += 1\n",
    "    else:\n",
    "        # No prediction file or empty file\n",
    "        prediction_string = \"no box\"\n",
    "        images_without_preds += 1\n",
    "\n",
    "    submission_data.append(\n",
    "        {\"image_id\": image_id, \"prediction_string\": prediction_string}\n",
    "    )\n",
    "\n",
    "# Create DataFrame with correct column names (lowercase!)\n",
    "submission_df = pd.DataFrame(submission_data)\n",
    "submission_df = submission_df[[\"image_id\", \"prediction_string\"]]\n",
    "\n",
    "# Save to CSV\n",
    "submission_df.to_csv(output_csv, index=False)\n",
    "\n",
    "# Print statistics\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"SUBMISSION STATISTICS\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Total images:               {len(submission_df)}\")\n",
    "print(f\"Images with predictions:    {images_with_preds}\")\n",
    "print(f\"Images without predictions: {images_without_preds}\")\n",
    "print(f\"Total bounding boxes:       {total_boxes}\")\n",
    "if len(submission_df) > 0:\n",
    "    print(f\"Average boxes per image:    {total_boxes / len(submission_df):.2f}\")\n",
    "\n",
    "# Show sample\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"SAMPLE PREDICTIONS\")\n",
    "print(\"=\" * 70)\n",
    "display(submission_df.head(10))\n",
    "\n",
    "# Validation\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"FORMAT VALIDATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Check format\n",
    "errors = []\n",
    "if list(submission_df.columns) != [\"image_id\", \"prediction_string\"]:\n",
    "    errors.append(f\"!!! Wrong columns: {list(submission_df.columns)}\")\n",
    "else:\n",
    "    print(\"‚úì Columns correct: image_id, prediction_string\")\n",
    "\n",
    "if len(submission_df) != len(test_images_list):\n",
    "    errors.append(\"!!! Row count mismatch\")\n",
    "else:\n",
    "    print(f\"‚úì Row count correct: {len(submission_df)}\")\n",
    "\n",
    "# Validate prediction format (sample first 20)\n",
    "format_ok = True\n",
    "for idx in range(min(20, len(submission_df))):\n",
    "    pred_str = str(submission_df.iloc[idx][\"prediction_string\"])\n",
    "\n",
    "    if pred_str == \"no box\":\n",
    "        continue\n",
    "\n",
    "    values = pred_str.split()\n",
    "    if len(values) % 6 != 0:\n",
    "        format_ok = False\n",
    "        break\n",
    "\n",
    "if format_ok:\n",
    "    print(\"‚úì All sampled predictions properly formatted (6 values per box)\")\n",
    "else:\n",
    "    errors.append(\"!!! Some predictions have wrong format\")\n",
    "\n",
    "if errors:\n",
    "    print(\"\\n!!! VALIDATION FAILED:\")\n",
    "    for err in errors:\n",
    "        print(f\"  {err}\")\n",
    "else:\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚úÖ SUBMISSION READY FOR KAGGLE!\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nFile: {output_csv}\")\n",
    "print(\"\\n Upload 'submission.csv' to Kaggle!\")\n",
    "print(\"\\n Tips:\")\n",
    "print(\"   - Check your score on the public leaderboard\")\n",
    "print(\"   - You have 3 submissions per day (use them wisely!)\")\n",
    "print(\"   - Select up to 2 final submissions for judging\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Phase 2 Complete! Now Begins the Real Competition\n",
    "\n",
    "### üèÜ What You've Accomplished:\n",
    "‚úÖ **Phase 1**: Registered dataset with 3LC Tables  \n",
    "‚úÖ **Phase 2**: Trained baseline YOLOv8n, inspected the Run in the 3LC Dashboard and made first submission  \n",
    "\n",
    "### The baseline is just your starting point. Now comes the actual competition work!\n",
    "\n",
    "---\n",
    "\n",
    "## Phase 3: Iterative Optimization (The Train‚ÄìFix‚ÄìRetrain Loop)\n",
    "\n",
    "This is where you'll actually improve your score. **The model is fixed (YOLOv8n), so improvements MUST come from data.**\n",
    "\n",
    "### Step-by-Step Iterative Workflow:\n",
    "\n",
    "#### 1. Analyze Data Gaps (Use 3LC Dashboard)\n",
    "Visit your 3LC Dashboard and inspect your Run:\n",
    "\n",
    "**Look for these error patterns:**\n",
    "\n",
    "##### A. False Negatives \n",
    "- **What it is**: Model fails to detect a weed that's actually present in the image\n",
    "- **How to identify in 3LC**: \n",
    "  - High confidence predictions with low/zero IoU (model predicts something not in ground truth)\n",
    "  - Visual inspection shows weed is present but unlabeled in training data\n",
    "- **Common causes**: \n",
    "  - **Missing labels**: Objects exist but weren't annotated during labeling (data quality issue)\n",
    "  - Insufficient training examples of that weed type or appearance\n",
    "- **Fix**: Add missing annotations to training data using Dashboard editor\n",
    "- **Learn more**: [Edit tables in Dashboard](https://docs.3lc.ai/3lc/latest/how-to/basics/edit-table.html)\n",
    "\n",
    "##### B. False Positives\n",
    "- **What it is**: Model predicts a weed where there isn't one\n",
    "- **How to identify in 3LC**: \n",
    "  - Predictions with low IoU to any ground truth box\n",
    "  - Visual inspection shows no weed at predicted location\n",
    "- **Common causes**: \n",
    "  - Similar-looking objects mislabeled as weeds in training data\n",
    "  - Model overfitting to spurious patterns (soil, shadows, debris)\n",
    "- **Fix**: Remove incorrect labels, add negative examples (images without weeds)\n",
    "\n",
    "##### C. Class Confusion (Wrong Class Predicted)\n",
    "- **What it is**: Model detects a weed but assigns wrong class (e.g., predicts \"carpetweed\" when it's \"morningglory\")\n",
    "- **How to identify in 3LC**: \n",
    "  - High IoU but wrong class assignment\n",
    "  - Compare predicted class vs ground truth class\n",
    "- **Common causes**: \n",
    "  - Visually similar weed species\n",
    "  - Inconsistent labeling in training data (same weed labeled differently)\n",
    "- **Fix**: Correct mislabeled classes, add more distinguishing examples\n",
    "\n",
    "##### D. Poor Localization (Inaccurate Bounding Boxes)\n",
    "- **What it is**: Model detects weed and correct class, but bounding box is inaccurate\n",
    "- **How to identify in 3LC**: \n",
    "  - Correct class but low IoU (e.g., IoU between 0.3-0.5)\n",
    "  - Bounding box too large, too small, or misaligned\n",
    "- **Common causes**: \n",
    "  - Inconsistent annotation conventions (tight vs loose boxes)\n",
    "  - Partially labeled objects in training data\n",
    "- **Fix**: Standardize bounding box annotations, correct misoriented boxes\n",
    "\n",
    "#### 2. Find and Fix Data Issues in Dashboard\n",
    "Use 3LC Dashboard workflows:\n",
    "\n",
    "**Step 1: Filter problematic samples**\n",
    "- Sort predictions by confidence, IoU, or class\n",
    "- Create custom filters (e.g., \"high confidence + low IoU\" = likely missing labels)\n",
    "- Group by error type\n",
    "\n",
    "**Step 2: Visual review**\n",
    "- Compare model predictions vs ground truth side-by-side\n",
    "- Look for patterns in failures (certain lighting, weed sizes, occlusions)\n",
    "\n",
    "**Step 3: Edit data directly in Dashboard**\n",
    "- Add missing bounding boxes\n",
    "- Correct wrong class labels\n",
    "- Remove incorrect annotations\n",
    "- Adjust misaligned bounding boxes\n",
    "\n",
    "**Step 4: Export edited table**\n",
    "- Dashboard creates a new table version automatically\n",
    "- Copy the table URL for retraining (see Step 3.5 above)\n",
    "\n",
    "**Learn more**: [Dashboard editing guide](https://docs.3lc.ai/3lc/latest/how-to/basics/edit-table.html)\n",
    "\n",
    "#### 3. Load Edited Table for Retraining\n",
    "\n",
    "After editing your data in the Dashboard:\n",
    "\n",
    "**Option A: Use table URL (Recommended)**\n",
    "```python\n",
    "# Copy the edited table URL from Dashboard\n",
    "train_table_v2 = tlc.Table.from_url(\"your_edited_table_url_here\")\n",
    "val_table_unchanged = val_table.latest()  # Keep val unchanged for fair comparison\n",
    "\n",
    "tables_v2 = {\n",
    "    \"train\": train_table_v2,\n",
    "    \"val\": val_table_unchanged\n",
    "}\n",
    "```\n",
    "\n",
    "**Option B: Use .latest() to get most recent version**\n",
    "```python\n",
    "# Automatically loads the newest version of your table\n",
    "train_table_v2 = train_table.latest()\n",
    "val_table_unchanged = val_table.latest()\n",
    "\n",
    "tables_v2 = {\n",
    "    \"train\": train_table_v2,\n",
    "    \"val\": val_table_unchanged\n",
    "}\n",
    "```\n",
    "\n",
    "#### 4. Retrain with Improved Data\n",
    "```python\n",
    "# Create new run with improved data\n",
    "RUN_NAME = \"yolov8n_with_fixed_labels_v2\"\n",
    "RUN_DESCRIPTION = \"Fixed class confusion between carpetweed and morningglory\"\n",
    "\n",
    "settings_v2 = Settings(\n",
    "    project_name=PROJECT_NAME,\n",
    "    run_name=RUN_NAME,\n",
    "    run_description=RUN_DESCRIPTION,\n",
    ")\n",
    "\n",
    "tables_v2 = {\n",
    "    \"train\": train_table_v2,\n",
    "    \"val\": val_table  # Keep val unchanged for fair comparison\n",
    "}\n",
    "\n",
    "# Retrain\n",
    "model_v2 = YOLO(\"yolov8n.pt\")\n",
    "results_v2 = model_v2.train(\n",
    "    tables=tables_v2,\n",
    "    epochs=EPOCHS,\n",
    "    imgsz=IMAGE_SIZE,\n",
    "    batch=BATCH_SIZE,\n",
    "    device=DEVICE,\n",
    "    workers=WORKERS,\n",
    "    settings=settings_v2,\n",
    "    val=True,\n",
    ")\n",
    "```\n",
    "\n",
    "#### 5. Compare Runs in 3LC Dashboard\n",
    "- View both runs side-by-side\n",
    "- Compare mAP@0.5 improvements\n",
    "- Identify which data fixes helped most\n",
    "- Plan next iteration\n",
    "\n",
    "#### 6. Repeat the Loop\n",
    "Each iteration should:\n",
    "1. Fix a specific data issue identified from previous run\n",
    "2. Document what you changed (in run description)\n",
    "3. Retrain and measure improvement\n",
    "4. Generate new Kaggle submission (3 per day limit)\n",
    "\n",
    "---\n",
    "\n",
    "## Phase 4: Advanced Data-Centric Techniques\n",
    "\n",
    "Once you've fixed obvious label issues, try these advanced approaches:\n",
    "\n",
    "### 1. Hard Example Mining\n",
    "Use 3LC to identify:\n",
    "- Low-confidence correct predictions (model unsure but right)\n",
    "- High-confidence wrong predictions (model confident but wrong)\n",
    "These are your most valuable training samples!\n",
    "\n",
    "### 2. Class Rebalancing & Sample Weighting\n",
    "\n",
    "If one class performs poorly:\n",
    "- Add more diverse examples of that class\n",
    "- Oversample underrepresented classes in your training data\n",
    "- Apply class-specific augmentation\n",
    "- Use 3LC Dashboard to apply sample weights and rebalance training distribution \n",
    "\n",
    "\n",
    "\n",
    "**Pro Tip**: 3LC Dashboard allows you to:\n",
    "- Weight samples by confidence, IoU, or custom metrics\n",
    "- Create stratified training splits\n",
    "- Oversample hard examples automatically\n",
    "- Balance class distributions without duplicating files\n",
    "\n",
    "### 3. Augmentation Tuning (Allowed!)\n",
    "```python\n",
    "# Experiment with augmentation hyperparameters:\n",
    "model.train(\n",
    "    tables=tables,\n",
    "    epochs=EPOCHS,\n",
    "    # Augmentation params:\n",
    "    hsv_h=0.015,      # Hue shifts (lighting changes)\n",
    "    hsv_s=0.7,        # Saturation (weather variations)\n",
    "    hsv_v=0.4,        # Brightness\n",
    "    degrees=10,       # Rotation (camera angles)\n",
    "    translate=0.1,    # Position shifts\n",
    "    scale=0.5,        # Size variation\n",
    "    fliplr=0.5,       # Horizontal flip\n",
    "    mosaic=1.0,       # Mosaic augmentation\n",
    "    mixup=0.1,        # Mixup augmentation\n",
    "    copy_paste=0.1,   # Copy-paste augmentation\n",
    ")\n",
    "```\n",
    "\n",
    "### 4. Hyperparameter Tuning\n",
    "```python\n",
    "# Experiment with:\n",
    "# - Learning rate: lr0=0.001, 0.005, 0.01, 0.02\n",
    "# - Batch size: 8, 16, 32 (GPU memory permitting)\n",
    "# - Epochs: 30, 50, 75, 100 (watch for overfitting)\n",
    "# - Warmup epochs: warmup_epochs=3, 5, 10\n",
    "# - Optimizer: optimizer='Adam', 'AdamW', 'SGD'\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Your Success Strategy\n",
    "1. Visit your 3LC Dashboard\n",
    "2. Analyze where your model fails\n",
    "3. Fix those data issues\n",
    "4. Retrain with better data (updated tables)\n",
    "5. Submit improved predictions\n",
    "6. Repeat!\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö†Ô∏è Competition Rules Reminder\n",
    "\n",
    "### ‚úÖ ALLOWED:\n",
    "- YOLOv8n model only (REQUIRED)\n",
    "- 640 input size (FIXED)\n",
    "- Hyperparameter tuning\n",
    "- Data augmentation (training-time)\n",
    "- Label corrections and improvements\n",
    "- Multiple training runs\n",
    "- Confidence threshold adjustment\n",
    "- 3 submissions per day\n",
    "\n",
    "### ‚ùå PROHIBITED:\n",
    "- Larger models (YOLOv8s, YOLOv8m, etc.)\n",
    "- Model ensembles\n",
    "- Model stacking\n",
    "- Different architectures\n",
    "- Post-processing beyond standard NMS\n",
    "- External data sources\n",
    "- Test-Time Augmentation (TTA) - prohibited due to edge device inference speed requirements\n",
    "\n",
    "---\n",
    "\n",
    "## Professional Skills You're Developing\n",
    "\n",
    "### Data-Centric AI Mastery:\n",
    "‚úÖ **Using model feedback** to identify data problems  \n",
    "‚úÖ **Systematic error analysis** via 3LC Dashboard  \n",
    "‚úÖ **Iterative improvement loops** (train‚Äìfix‚Äìretrain)  \n",
    "‚úÖ **Version control for datasets** (tracking data changes)  \n",
    "‚úÖ **Reproducible experiments** (every run documented)  \n",
    "\n",
    "### Production AI Reality:\n",
    "‚úÖ **Working within strict constraints** (model, compute, memory)  \n",
    "‚úÖ **Data quality as primary lever** (when model can't scale)  \n",
    "‚úÖ **Systematic rather than random** improvements  \n",
    "‚úÖ **Documentation and tracking** for team collaboration  \n",
    "\n",
    "### These are the skills production AI teams use every day!\n",
    "\n",
    "---\n",
    "\n",
    "## Resources & Support\n",
    "\n",
    "### 3LC Documentation:\n",
    "- **Tables**: https://docs.3lc.ai/3lc/latest/user-guide/python-package/core-concepts/tables.html\n",
    "- **Runs**: https://docs.3lc.ai/3lc/latest/user-guide/python-package/core-concepts/runs.html\n",
    "- **YOLO Integration**: https://github.com/3lc-ai/3lc-ultralytics\n",
    "\n",
    "### YOLOv8 Documentation:\n",
    "- **Training Guide**: https://docs.ultralytics.com/modes/train/\n",
    "- **Hyperparameters**: https://docs.ultralytics.com/usage/cfg/\n",
    "- **Augmentation**: https://docs.ultralytics.com/guides/preprocessing_annotated_data/\n",
    "\n",
    "### Competition Support:\n",
    "- **Discussion Forum**: Share insights and strategies\n",
    "- **Leaderboard**: 50% public, 50% private (prevents overfitting)\n",
    "- **Submission Limit**: 3 per day, choose 2 final\n",
    "\n",
    "\n",
    "**Good luck! May your data improve with every iteration!** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Ready for Faster Iteration? Use the Scripts!\n",
    "\n",
    "Congratulations! You've completed the starter notebook and learned the data-centric AI workflow. \n",
    "\n",
    "### Switch to Production-Ready Scripts\n",
    "\n",
    "The training and prediction workflow you just learned has been packaged into simple, easy-to-edit scripts for faster experimentation:\n",
    "\n",
    "#### üìÑ Available Scripts\n",
    "\n",
    "**`train.py`** - Train models with 3LC tracking\n",
    "- Simple edit-in-place configuration at the top of the file\n",
    "- Just modify variables (like RUN_NAME, EPOCHS, TRAIN_TABLE_URL) and run\n",
    "- Auto-loads latest table versions or specific edited tables from Dashboard\n",
    "\n",
    "**`predict.py`** - Generate predictions and submissions\n",
    "- Edit configuration section to set model weights path\n",
    "- Creates Kaggle-ready CSV with automatic validation\n",
    "- Adjustable confidence thresholds\n",
    "\n",
    "---\n",
    "\n",
    "### How to Use\n",
    "\n",
    "Both scripts work the same way:\n",
    "\n",
    "1. **Open the script** in your editor (VS Code, PyCharm, Notepad++, etc.)\n",
    "2. **Edit the CONFIGURATION section** at the top:\n",
    "   - Change run names, epochs, table URLs, etc.\n",
    "   - All settings are clearly labeled with comments\n",
    "3. **Run the script** - that's it!\n",
    "\n",
    "**No command-line arguments to remember!** Just edit and run.\n",
    "\n",
    "---\n",
    "\n",
    "### Quick Examples\n",
    "\n",
    "#### Training Example\n",
    "\n",
    "**Step 1:** Open `train.py` and edit the configuration:\n",
    "```python\n",
    "# ============================================================================\n",
    "# CONFIGURATION - Edit these values for your training run\n",
    "# ============================================================================\n",
    "\n",
    "# 3LC Table URLs (get these from Dashboard)\n",
    "TRAIN_TABLE_URL = \"your/train/table/url\"\n",
    "VAL_TABLE_URL = \"your/val/table/url\"\n",
    "\n",
    "# Run configuration\n",
    "RUN_NAME = \"v1_baseline\"  # Change for each experiment\n",
    "RUN_DESCRIPTION = \"Baseline YOLOv8n training run\"\n",
    "\n",
    "# Training hyperparameters\n",
    "EPOCHS = 5  # Number of training epochs\n",
    "BATCH_SIZE = 16  # Batch size\n",
    "DEVICE = 0  # GPU device (0 for first GPU, 'cpu' for CPU)\n",
    "\n",
    "# Data augmentation\n",
    "USE_AUGMENTATION = False  # Set to True to enable mosaic, mixup, copy_paste\n",
    "```\n",
    "\n",
    "**Step 2:** Run the script:\n",
    "```bash\n",
    "python train.py\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Prediction Example\n",
    "\n",
    "**Step 1:** Open `predict.py` and edit the configuration:\n",
    "```python\n",
    "# ============================================================================\n",
    "# CONFIGURATION - Edit these values\n",
    "# ============================================================================\n",
    "\n",
    "# Model weights path (from training)\n",
    "MODEL_WEIGHTS = \"runs/detect/yolov8n_baseline/weights/best.pt\"\n",
    "\n",
    "# Inference settings\n",
    "CONFIDENCE_THRESHOLD = 0.25  # Confidence threshold for detections\n",
    "IMAGE_SIZE = 640  # Input image size (FIXED by competition)\n",
    "DEVICE = 0  # GPU device (0 for first GPU, 'cpu' for CPU)\n",
    "\n",
    "# Output\n",
    "OUTPUT_CSV = \"submission.csv\"  # Output submission file\n",
    "```\n",
    "\n",
    "**Step 2:** Run the script:\n",
    "```bash\n",
    "python predict.py\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Why Use Scripts?\n",
    "\n",
    "| Notebook | Scripts |\n",
    "|----------|---------|\n",
    "| ‚úÖ Learn concepts | ‚úÖ Fast iteration |\n",
    "| ‚úÖ Visual explanations | ‚úÖ Easy to customize |\n",
    "| ‚úÖ Step-by-step guide | ‚úÖ No cell dependencies |\n",
    "| ‚úÖ Interactive exploration | ‚úÖ One command runs all |\n",
    "|  Slower (run cells) |  Faster workflow |\n",
    "\n",
    "**You've learned the \"why\" in this notebook. Now use the scripts for the \"how\" in your iterations!**\n",
    "\n",
    "---\n",
    "\n",
    "### Typical Workflow\n",
    "\n",
    "1. **Train baseline** (you just did this in the notebook!)\n",
    "\n",
    "2. **Switch to scripts** for faster iteration:\n",
    "   ```bash\n",
    "   # Edit train.py configuration, then:\n",
    "   python train.py\n",
    "   ```\n",
    "\n",
    "3. **Generate predictions:**\n",
    "   ```bash\n",
    "   # Edit predict.py configuration if needed, then:\n",
    "   python predict.py\n",
    "   ```\n",
    "\n",
    "4. **Analyze in Dashboard:**\n",
    "   - Open your run in 3LC Dashboard\n",
    "   - Identify data issues (missing labels, mislabels, etc.)\n",
    "   - Edit the table directly in Dashboard\n",
    "   - Copy the edited table URL\n",
    "\n",
    "5. **Retrain with fixed data:**\n",
    "   - Paste the edited table URL into `train.py`\n",
    "   - Change RUN_NAME to track the iteration (e.g., \"v3_fixed_labels\")\n",
    "   - Run `python train.py`\n",
    "\n",
    "6. **Submit and iterate!**\n",
    "   - Update MODEL_WEIGHTS in `predict.py` to your latest model\n",
    "   - Run `python predict.py`\n",
    "   - Upload `submission.csv` to Kaggle\n",
    "\n",
    "---\n",
    "\n",
    "### Script Features\n",
    "\n",
    "Both scripts include:\n",
    "- ‚úÖ **Clear configuration section** - all settings in one place at the top\n",
    "- ‚úÖ **Helpful comments** - explains what each setting does\n",
    "- ‚úÖ **Auto-validation** - checks for missing files and invalid settings\n",
    "- ‚úÖ **Progress tracking** - clear output showing what's happening\n",
    "- ‚úÖ **Error messages** - tells you exactly what went wrong and how to fix it\n",
    "- ‚úÖ **Easy to customize** - modify the pipeline code if needed\n",
    "\n",
    "---\n",
    "\n",
    "### Learn More\n",
    "\n",
    "- **Script source code**: Both scripts are well-commented - read them to understand implementation details\n",
    "- **README.md**: Complete documentation with more examples\n",
    "- **3LC Dashboard workflow**: The scripts integrate seamlessly with Dashboard editing\n",
    "\n",
    "---\n",
    "\n",
    "**üéØ Bottom Line:** The notebook taught you the concepts. The scripts help you iterate faster with less friction!\n",
    "\n",
    "**Ready to iterate? Open `train.py`, make your edits, and run!** üåæ\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3lc-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
